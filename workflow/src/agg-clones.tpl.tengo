ll := import("@platforma-sdk/workflow-tengo:ll")
self := import("@platforma-sdk/workflow-tengo:tpl")
pConstants := import("@platforma-sdk/workflow-tengo:pframes.constants")
slices := import("@platforma-sdk/workflow-tengo:slices")
assets := import("@platforma-sdk/workflow-tengo:assets")
exec := import("@platforma-sdk/workflow-tengo:exec")
units := import("@platforma-sdk/workflow-tengo:units")
math := import("math")

json := import("json")

self.defineOutputs("tsv")

ptransformSw := assets.importSoftware("@platforma-open/milaboratories.software-ptransform:main")

self.body(func(inputs) {
	inputData := inputs[pConstants.VALUE_FIELD_NAME]
	inputDataMeta := inputData.getDataAsJson()
	inputMap := inputData.inputs()
	numberOfSamples := len(inputMap)

	ll.assert(inputDataMeta.keyLength == 1, "unexpected number of aggregation axes")

	mainAbundanceColumn := inputs.mainAbundanceColumn
	cloneColumns := inputs.cloneColumns

	// Adding clonotypeKey column
	pWorkflow := {
		steps: [ {
			type: "aggregate",
			groupBy: ["clonotypeKey"],
			aggregations: [ {
				type: "max_by",
				rankingCol: mainAbundanceColumn,
				pickCols: slices.map(cloneColumns, func(col) {
					return [col, col]
				})
			} ]
		} ]
	}

	aggregateBuilderCmd := exec.builder().
		printErrStreamToStdout().
		software(ptransformSw).
		mem(int(math.max(numberOfSamples, 64)) * units.GiB).
		cpu(int(math.max(numberOfSamples, 32))).
		arg("--workflow").arg("wf.json").
		writeFile("wf.json", json.encode(pWorkflow))

	for sKey, inputFile in inputMap {
		key := json.decode(sKey)
		if len(key) != 1 {
			ll.panic("malformed key: %v", sKey)
		}
		sampleId := key[0]
		aggregateBuilderCmd.
			arg(sampleId + ".tsv").
			addFile(sampleId + ".tsv", inputFile)
	}

	aggregateCmd := aggregateBuilderCmd.
		arg("output.tsv").saveFile("output.tsv").
		run()

	processedTsv := aggregateCmd.getFile("output.tsv")

	return {
		tsv: processedTsv
	}
})
