ll := import("@platforma-sdk/workflow-tengo:ll")
self := import("@platforma-sdk/workflow-tengo:tpl")
pConstants := import("@platforma-sdk/workflow-tengo:pframes.constants")
slices := import("@platforma-sdk/workflow-tengo:slices")
maps := import("@platforma-sdk/workflow-tengo:maps")
units := import("@platforma-sdk/workflow-tengo:units")
pt := import("@platforma-sdk/workflow-tengo:pt")
math := import("math")
json := import("json")

self.defineOutputs("tsv", "linker")

self.body(func(inputs) {
	inputData := inputs[pConstants.VALUE_FIELD_NAME]
	inputDataMeta := inputData.getDataAsJson()
	inputMap := inputData.inputs()
	numberOfSamples := len(inputMap)

	ll.assert(inputDataMeta.keyLength == 1, "unexpected number of aggregation axes")

	mainAbundanceColumn := inputs.mainAbundanceColumn
	cloneColumns := inputs.cloneColumns

	memGB := int(math.max(numberOfSamples, 64))

	wf := pt.workflow().
		inMediumQueue().
		mem(memGB * units.GiB).
		cpu(int(math.max(numberOfSamples, 32)))

	dataFrames := []

	// Load all input files and add sampleId column
	for sKey in maps.getKeys(inputMap) {
		inputFile := inputMap[sKey]
		key := json.decode(sKey)
		if len(key) != 1 {
			ll.panic("malformed key: %v", sKey)
		}
		sampleId := key[0]
		dfId := "table_" + sampleId

		df := wf.frame({
			file: inputFile,
			xsvType: "tsv"
		}, {
			id: dfId,
			inferSchema: true
		})
		// Add sampleId column to each dataframe
		df.addColumns(pt.lit(sampleId).alias("sampleId"))
		dataFrames = append(dataFrames, df)
	}

	currentDf := undefined
	if len(dataFrames) == 0 {
		ll.panic("no input files found")
	} else if len(dataFrames) == 1 {
		currentDf = dataFrames[0]
	} else {
		currentDf = pt.concat(dataFrames)
	}

	// Create aggregations using maxBy for each clone column
	aggExpressions := []
	for col in cloneColumns {
		aggExpressions = append(aggExpressions,
			pt.col(col).maxBy(pt.col(mainAbundanceColumn)).alias(col)
		)
	}

	// Aggregate by clonotypeKey
	aggregatedDf := currentDf.groupBy("clonotypeKey").agg(aggExpressions...)
	aggregatedDf.save("output.tsv")

	// Create linker dataframe with unique (sampleId, clonotypeKey) combinations from original data
	dfLinker := currentDf.select(pt.col("sampleId"), pt.col("clonotypeKey"))
	dfLinker = dfLinker.unique()
	dfLinker.addColumns(pt.lit(1).alias("link"))
	dfLinker.save("linker.tsv")

	ptablerResult := wf.run()

	processedTsv := ptablerResult.getFile("output.tsv")
	linkerTsv := ptablerResult.getFile("linker.tsv")

	return {
		tsv: processedTsv,
		linker: linkerTsv
	}
})
